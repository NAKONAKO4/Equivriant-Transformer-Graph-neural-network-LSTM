{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:53:52.718352Z",
     "start_time": "2024-05-16T12:53:50.933097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.nn import ExtractIr, FullyConnectedNet, Gate\n",
    "from e3nn.o3 import FullyConnectedTensorProduct, TensorProduct\n",
    "from e3nn.util.jit import compile_mode\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ],
   "id": "651d3c30458c5744",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:54:13.830550Z",
     "start_time": "2024-05-16T12:54:13.750916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scatter(src: torch.Tensor, index: torch.Tensor, dim_size: int) -> torch.Tensor:\n",
    "    # special case of torch_scatter.scatter with dim=0\n",
    "    out = src.new_zeros(dim_size, src.shape[1])\n",
    "    index = index.reshape(-1, 1).expand_as(src)\n",
    "    return out.scatter_add_(0, index, src)\n",
    "\n",
    "\n",
    "def radius_graph(pos, r_max, batch) -> torch.Tensor:\n",
    "    # naive and inefficient version of torch_cluster.radius_graph\n",
    "    r = torch.cdist(pos, pos)\n",
    "    index = ((r < r_max) & (r > 0)).nonzero().T\n",
    "    index = index[:, batch[index[0]] == batch[index[1]]]\n",
    "    return index\n",
    "\n",
    "\n",
    "@compile_mode(\"script\")\n",
    "class Convolution(torch.nn.Module):\n",
    "    r\"\"\"equivariant convolution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in : `e3nn.o3.Irreps`\n",
    "        representation of the input node features\n",
    "\n",
    "    irreps_node_attr : `e3nn.o3.Irreps`\n",
    "        representation of the node attributes\n",
    "\n",
    "    irreps_edge_attr : `e3nn.o3.Irreps`\n",
    "        representation of the edge attributes\n",
    "\n",
    "    irreps_out : `e3nn.o3.Irreps` or None\n",
    "        representation of the output node features\n",
    "\n",
    "    number_of_edge_features : int\n",
    "        number of scalar (0e) features of the edge used to feed the FC network\n",
    "\n",
    "    radial_layers : int\n",
    "        number of hidden layers in the radial fully connected network\n",
    "\n",
    "    radial_neurons : int\n",
    "        number of neurons in the hidden layers of the radial fully connected network\n",
    "\n",
    "    num_neighbors : float\n",
    "        typical number of nodes convolved over\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        irreps_in: o3.Irreps,\n",
    "        irreps_node_attr: o3.Irreps,\n",
    "        irreps_edge_attr: o3.Irreps,\n",
    "        irreps_out: Optional[o3.Irreps],\n",
    "        number_of_edge_features: int,\n",
    "        radial_layers: int,\n",
    "        radial_neurons: int,\n",
    "        num_neighbors: float,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.irreps_in = o3.Irreps(irreps_in)\n",
    "        self.irreps_node_attr = o3.Irreps(irreps_node_attr)\n",
    "        self.irreps_edge_attr = o3.Irreps(irreps_edge_attr)\n",
    "        self.irreps_out = o3.Irreps(irreps_out)\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        self.sc = FullyConnectedTensorProduct(self.irreps_in, self.irreps_node_attr, self.irreps_out)\n",
    "\n",
    "        self.lin1 = FullyConnectedTensorProduct(self.irreps_in, self.irreps_node_attr, self.irreps_in)\n",
    "\n",
    "        irreps_mid = []\n",
    "        instructions = []\n",
    "        for i, (mul, ir_in) in enumerate(self.irreps_in):\n",
    "            for j, (_, ir_edge) in enumerate(self.irreps_edge_attr):\n",
    "                for ir_out in ir_in * ir_edge:\n",
    "                    if ir_out in self.irreps_out:\n",
    "                        k = len(irreps_mid)\n",
    "                        irreps_mid.append((mul, ir_out))\n",
    "                        instructions.append((i, j, k, \"uvu\", True))\n",
    "        irreps_mid = o3.Irreps(irreps_mid)\n",
    "        irreps_mid, p, _ = irreps_mid.sort()\n",
    "\n",
    "        instructions = [(i_1, i_2, p[i_out], mode, train) for i_1, i_2, i_out, mode, train in instructions]\n",
    "\n",
    "        tp = TensorProduct(\n",
    "            self.irreps_in,\n",
    "            self.irreps_edge_attr,\n",
    "            irreps_mid,\n",
    "            instructions,\n",
    "            internal_weights=False,\n",
    "            shared_weights=False,\n",
    "        )\n",
    "        self.fc = FullyConnectedNet(\n",
    "            [number_of_edge_features] + radial_layers * [radial_neurons] + [tp.weight_numel], torch.nn.functional.silu\n",
    "        )\n",
    "        self.tp = tp\n",
    "\n",
    "        self.lin2 = FullyConnectedTensorProduct(irreps_mid, self.irreps_node_attr, self.irreps_out)\n",
    "\n",
    "    def forward(self, node_input, node_attr, edge_src, edge_dst, edge_attr, edge_features) -> torch.Tensor:\n",
    "        weight = self.fc(edge_features)\n",
    "\n",
    "        x = node_input\n",
    "\n",
    "        s = self.sc(x, node_attr)\n",
    "        x = self.lin1(x, node_attr)\n",
    "\n",
    "        edge_features = self.tp(x[edge_src], edge_attr, weight)\n",
    "        x = scatter(edge_features, edge_dst, dim_size=x.shape[0]).div(self.num_neighbors**0.5)\n",
    "\n",
    "        x = self.lin2(x, node_attr)\n",
    "\n",
    "        c_s, c_x = math.sin(math.pi / 8), math.cos(math.pi / 8)\n",
    "        m = self.sc.output_mask\n",
    "        c_x = (1 - m) + c_x * m\n",
    "        return c_s * s + c_x * x\n",
    "\n",
    "\n",
    "def smooth_cutoff(x):\n",
    "    u = 2 * (x - 1)\n",
    "    y = (math.pi * u).cos().neg().add(1).div(2)\n",
    "    y[u > 0] = 0\n",
    "    y[u < -1] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def tp_path_exists(irreps_in1, irreps_in2, ir_out) -> bool:\n",
    "    irreps_in1 = o3.Irreps(irreps_in1).simplify()\n",
    "    irreps_in2 = o3.Irreps(irreps_in2).simplify()\n",
    "    ir_out = o3.Irrep(ir_out)\n",
    "\n",
    "    for _, ir1 in irreps_in1:\n",
    "        for _, ir2 in irreps_in2:\n",
    "            if ir_out in ir1 * ir2:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class Compose(torch.nn.Module):\n",
    "    def __init__(self, first, second) -> None:\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "        self.irreps_in = self.first.irreps_in\n",
    "        self.irreps_out = self.second.irreps_out\n",
    "\n",
    "    def forward(self, *input):\n",
    "        x = self.first(*input)\n",
    "        return self.second(x)\n",
    "\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    r\"\"\"equivariant neural network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in : `e3nn.o3.Irreps` or None\n",
    "        representation of the input features\n",
    "        can be set to ``None`` if nodes don't have input features\n",
    "\n",
    "    irreps_hidden : `e3nn.o3.Irreps`\n",
    "        representation of the hidden features\n",
    "\n",
    "    irreps_out : `e3nn.o3.Irreps`\n",
    "        representation of the output features\n",
    "\n",
    "    irreps_node_attr : `e3nn.o3.Irreps` or None\n",
    "        representation of the nodes attributes\n",
    "        can be set to ``None`` if nodes don't have attributes\n",
    "\n",
    "    irreps_edge_attr : `e3nn.o3.Irreps`\n",
    "        representation of the edge attributes\n",
    "        the edge attributes are :math:`h(r) Y(\\vec r / r)`\n",
    "        where :math:`h` is a smooth function that goes to zero at ``max_radius``\n",
    "        and :math:`Y` are the spherical harmonics polynomials\n",
    "\n",
    "    layers : int\n",
    "        number of gates (non linearities)\n",
    "\n",
    "    max_radius : float\n",
    "        maximum radius for the convolution\n",
    "\n",
    "    number_of_basis : int\n",
    "        number of basis on which the edge length are projected\n",
    "\n",
    "    radial_layers : int\n",
    "        number of hidden layers in the radial fully connected network\n",
    "\n",
    "    radial_neurons : int\n",
    "        number of neurons in the hidden layers of the radial fully connected network\n",
    "\n",
    "    num_neighbors : float\n",
    "        typical number of nodes at a distance ``max_radius``\n",
    "\n",
    "    num_nodes : float\n",
    "        typical number of nodes in a graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken,\n",
    "        d_model,\n",
    "        nhead,\n",
    "        d_hid,\n",
    "        nlayers,\n",
    "        dropout,\n",
    "\n",
    "        irreps_in: o3.Irreps,\n",
    "        irreps_hidden: o3.Irreps,\n",
    "        irreps_out: o3.Irreps,\n",
    "        irreps_node_attr: o3.Irreps,\n",
    "        irreps_edge_attr: o3.Irreps,\n",
    "        layers: int,\n",
    "        max_radius: float,\n",
    "        number_of_basis: int,\n",
    "        radial_layers: int,\n",
    "        radial_neurons: int,\n",
    "        num_neighbors: float,\n",
    "        num_nodes: float,\n",
    "        reduce_output: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.max_radius = max_radius\n",
    "        self.number_of_basis = number_of_basis\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.num_nodes = num_nodes\n",
    "        self.reduce_output = reduce_output\n",
    "\n",
    "        self.irreps_in = o3.Irreps(irreps_in) if irreps_in is not None else None\n",
    "        self.irreps_hidden = o3.Irreps(irreps_hidden)\n",
    "        self.irreps_out = o3.Irreps(irreps_out)\n",
    "        self.irreps_node_attr = o3.Irreps(irreps_node_attr) if irreps_node_attr is not None else o3.Irreps(\"0e\")\n",
    "        self.irreps_edge_attr = o3.Irreps(irreps_edge_attr)\n",
    "\n",
    "        self.input_has_node_in = irreps_in is not None\n",
    "        self.input_has_node_attr = irreps_node_attr is not None\n",
    "\n",
    "        self.ext_z = ExtractIr(self.irreps_node_attr, \"0e\")\n",
    "        number_of_edge_features = number_of_basis + 2 * self.irreps_node_attr.count(\"0e\")\n",
    "\n",
    "        irreps = self.irreps_in if self.irreps_in is not None else o3.Irreps(\"0e\")\n",
    "\n",
    "        act = {\n",
    "            1: torch.nn.functional.silu,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "        act_gates = {\n",
    "            1: torch.sigmoid,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(layers):\n",
    "            irreps_scalars = o3.Irreps(\n",
    "                [\n",
    "                    (mul, ir)\n",
    "                    for mul, ir in self.irreps_hidden\n",
    "                    if ir.l == 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)\n",
    "                ]\n",
    "            )\n",
    "            irreps_gated = o3.Irreps(\n",
    "                [(mul, ir) for mul, ir in self.irreps_hidden if ir.l > 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)]\n",
    "            )\n",
    "            ir = \"0e\" if tp_path_exists(irreps, self.irreps_edge_attr, \"0e\") else \"0o\"\n",
    "            irreps_gates = o3.Irreps([(mul, ir) for mul, _ in irreps_gated])\n",
    "\n",
    "            gate = Gate(\n",
    "                irreps_scalars,\n",
    "                [act[ir.p] for _, ir in irreps_scalars],  # scalar\n",
    "                irreps_gates,\n",
    "                [act_gates[ir.p] for _, ir in irreps_gates],  # gates (scalars)\n",
    "                irreps_gated,  # gated tensors\n",
    "            )\n",
    "            conv = Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                gate.irreps_in,\n",
    "                number_of_edge_features,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors,\n",
    "            )\n",
    "            irreps = gate.irreps_out\n",
    "            self.layers.append(Compose(conv, gate))\n",
    "\n",
    "        self.layers.append(\n",
    "            Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                self.irreps_out,\n",
    "                number_of_edge_features,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors,\n",
    "            )\n",
    "        )\n",
    "        self.transformer = TransformerModel(ntoken, d_model, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor],src_mask) -> torch.Tensor:\n",
    "        \"\"\"evaluate the network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `torch_geometric.data.Data` or dict\n",
    "            data object containing\n",
    "            - ``pos`` the position of the nodes (atoms)\n",
    "            - ``x`` the input features of the nodes, optional\n",
    "            - ``z`` the attributes of the nodes, for instance the atom type, optional\n",
    "            - ``batch`` the graph to which the node belong, optional\n",
    "        \"\"\"\n",
    "        if \"batch\" in data:\n",
    "            batch = data[\"batch\"]\n",
    "        else:\n",
    "            batch = data[\"pos\"].new_zeros(data[\"pos\"].shape[0], dtype=torch.long)\n",
    "\n",
    "        edge_index = radius_graph(data[\"pos\"], self.max_radius, batch)\n",
    "        edge_src = edge_index[0]\n",
    "        edge_dst = edge_index[1]\n",
    "        edge_vec = data[\"pos\"][edge_src] - data[\"pos\"][edge_dst]\n",
    "        edge_sh = o3.spherical_harmonics(self.irreps_edge_attr, edge_vec, True, normalization=\"component\")\n",
    "        edge_length = edge_vec.norm(dim=1)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_length, start=0.0, end=self.max_radius, number=self.number_of_basis, basis=\"gaussian\", cutoff=False\n",
    "        ).mul(self.number_of_basis**0.5)\n",
    "        edge_attr = smooth_cutoff(edge_length / self.max_radius)[:, None] * edge_sh\n",
    "\n",
    "        if self.input_has_node_in and \"x\" in data:\n",
    "            assert self.irreps_in is not None\n",
    "            x = data[\"x\"]\n",
    "        else:\n",
    "            assert self.irreps_in is None\n",
    "            x = data[\"pos\"].new_ones((data[\"pos\"].shape[0], 1))\n",
    "\n",
    "        if self.input_has_node_attr and \"z\" in data:\n",
    "            z = data[\"z\"]\n",
    "        else:\n",
    "            assert self.irreps_node_attr == o3.Irreps(\"0e\")\n",
    "            z = data[\"pos\"].new_ones((data[\"pos\"].shape[0], 1))\n",
    "\n",
    "        scalar_z = self.ext_z(z)\n",
    "        edge_features = torch.cat([edge_length_embedded, scalar_z[edge_src], scalar_z[edge_dst]], dim=1)\n",
    "\n",
    "        for lay in self.layers:\n",
    "            x = lay(x, z, edge_src, edge_dst, edge_attr, edge_features)\n",
    "        x = x.long()\n",
    "        x = self.transformer(x, src_mask)\n",
    "        x = x.float()\n",
    "        if self.reduce_output:\n",
    "            return scatter(x, batch, dim_size=int(batch.max()) + 1).div(self.num_nodes**0.5)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "8b2fde094038b38b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:54:35.319629Z",
     "start_time": "2024-05-16T12:54:35.312317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, d_model, nhead, d_hid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "# 辅助的位置编码类\n",
    "'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model // 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ],
   "id": "ea0908293ed2098",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:03:18.714009Z",
     "start_time": "2024-05-16T13:03:18.706493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_random_graph_data(num_nodes, max_radius, num_features):\n",
    "    # 生成随机三维坐标\n",
    "    positions = torch.randn(num_nodes, 3)\n",
    "\n",
    "    # 计算所有节点对之间的距离\n",
    "    distance_matrix = torch.cdist(positions, positions)\n",
    "\n",
    "    # 确定邻居（即距离小于最大半径的节点）\n",
    "    edge_index = (distance_matrix < max_radius) & (distance_matrix > 0)  # 排除自环\n",
    "    edge_index = edge_index.nonzero(as_tuple=False).t()\n",
    "\n",
    "    # 生成每个节点的特征\n",
    "    x = torch.randn(num_nodes, num_features)\n",
    "\n",
    "    # 创建 PyTorch Geometric Data 对象\n",
    "    data = Data(x=x, edge_index=edge_index, pos=positions)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 设定参数\n",
    "'''num_nodes = 100  # 节点数\n",
    "max_radius = 3.0  # 最大半径\n",
    "num_features = 5  # 特征维度\n",
    "\n",
    "# 生成图数据\n",
    "graph_data = generate_random_graph_data(num_nodes, max_radius, num_features)\n",
    "\n",
    "# 显示数据信息\n",
    "print(\"Graph data:\", graph_data)\n",
    "print(\"Number of nodes:\", graph_data.num_nodes)\n",
    "print(\"Number of edges:\", graph_data.num_edges)\n",
    "print(\"Node features shape:\", graph_data.x.shape)\n",
    "print(\"Edge indices shape:\", graph_data.edge_index.shape)\n",
    "print(\"Positions shape:\", graph_data.pos.shape)\n",
    "'''\n",
    "# 接下来就可以将这个 graph_data 用于模型的训练了\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "def generate_graph_dataset(num_graphs, num_nodes, max_radius, num_features):\n",
    "    dataset = []\n",
    "    for _ in range(num_graphs):\n",
    "        data = generate_random_graph_data(num_nodes, max_radius, num_features)\n",
    "        dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "# 生成图数据集\n",
    "#num_graphs = 50  # 生成50张图\n",
    "#graph_dataset = generate_graph_dataset(num_graphs, num_nodes, max_radius, num_features)\n",
    "\n",
    "# 使用 DataLoader 加载数据集\n",
    "#graph_loader = DataLoader(graph_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 示例：遍历数据加载器\n",
    "'''\n",
    "for batch in graph_loader:\n",
    "    print(\"Batch size:\", batch.num_graphs)\n",
    "    print(\"Number of nodes in batch:\", batch.num_nodes)\n",
    "    print(\"Number of edges in batch:\", batch.num_edges)\n",
    "    # 此处可以调用模型进行训练步骤\n",
    "'''\n"
   ],
   "id": "982603abed37ee14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor batch in graph_loader:\\n    print(\"Batch size:\", batch.num_graphs)\\n    print(\"Number of nodes in batch:\", batch.num_nodes)\\n    print(\"Number of edges in batch:\", batch.num_edges)\\n    # 此处可以调用模型进行训练步骤\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:04:39.301134Z",
     "start_time": "2024-05-16T13:04:39.272486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成数据\n",
    "from torch import nn, optim\n",
    "num_features = 5  # 每个节点的特征维度\n",
    "d_model = 5  # Transformer中的特征维度\n",
    "nhead = 5  # 多头注意力中的头数\n",
    "d_hid = 256  # 前馈网络中的隐藏单元数量\n",
    "nlayers = 3  # Transformer堆栈中的层数\n",
    "dropout = 0.1  # Dropout比率\n",
    "max_radius = 3.0  # 最大半径定义邻居\n",
    "number_of_basis = 10  # 基函数数量\n",
    "radial_layers = 2  # 径向网络层数\n",
    "radial_neurons = 64  # 每个径向层的神经元数\n",
    "num_neighbors = 6  # 平均邻居数\n",
    "num_nodes = 100  # 节点数，用于归一化\n",
    "num_graphs = 40\n",
    "dataloader = generate_graph_dataset(num_graphs, num_nodes, max_radius, num_features)\n",
    "\n",
    "# 转换为数据加载器\n",
    "#dataset = TensorDataset(features, features)  # 假设我们在一个回归或自编码任务中使用特征作为目标\n",
    "#dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()"
   ],
   "id": "196720b44122a2e1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:05:18.438038Z",
     "start_time": "2024-05-16T13:05:18.435410Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader",
   "id": "5f7923c75d6b4745",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[100, 5], edge_index=[2, 7185], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7566], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8184], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7977], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7204], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7368], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7994], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8068], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8214], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7777], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7703], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7988], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8556], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8187], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7402], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7581], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7763], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7693], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7997], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8176], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7916], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8010], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7782], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7755], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7907], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7862], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8367], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7827], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8032], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7897], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7555], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7519], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7953], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7979], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8411], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7818], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 7407], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8036], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8272], pos=[100, 3]),\n",
       " Data(x=[100, 5], edge_index=[2, 8174], pos=[100, 3])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:56:16.106657Z",
     "start_time": "2024-05-16T12:56:15.218951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from e3nn import o3\n",
    "# 模型参数\n",
    "num_features = 5  # 每个节点的特征维度\n",
    "d_model = 5  # Transformer中的特征维度\n",
    "nhead = 8  # 多头注意力中的头数\n",
    "d_hid = 256  # 前馈网络中的隐藏单元数量\n",
    "nlayers = 3  # Transformer堆栈中的层数\n",
    "dropout = 0.1  # Dropout比率\n",
    "max_radius = 3.0  # 最大半径定义邻居\n",
    "number_of_basis = 10  # 基函数数量\n",
    "radial_layers = 2  # 径向网络层数\n",
    "radial_neurons = 64  # 每个径向层的神经元数\n",
    "num_neighbors = 6  # 平均邻居数\n",
    "num_nodes = 100  # 节点数，用于归一化\n",
    "num_graphs = 40\n",
    "# 初始化模型\n",
    "model = Network(\n",
    "\n",
    "    ntoken=num_features,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout,\n",
    "\n",
    "    irreps_in=o3.Irreps(\"5x0e\"),\n",
    "    irreps_hidden=o3.Irreps(\"10x0e + 5x1o\"),\n",
    "    irreps_out=o3.Irreps(\"5x0e\"),\n",
    "    irreps_node_attr=None,\n",
    "    irreps_edge_attr=o3.Irreps.spherical_harmonics(3),\n",
    "    layers=3,\n",
    "    max_radius=max_radius,\n",
    "    number_of_basis=number_of_basis,\n",
    "    radial_layers=radial_layers,\n",
    "    radial_neurons=radial_neurons,\n",
    "    num_neighbors=num_neighbors,\n",
    "    num_nodes=num_nodes,\n",
    "    reduce_output=False\n",
    ")\n",
    "\n",
    "# 生成数据\n",
    "dataloader = generate_graph_dataset(num_graphs, num_nodes, max_radius, num_features)\n",
    "\n",
    "# 转换为数据加载器\n",
    "#dataset = TensorDataset(features, features)  # 假设我们在一个回归或自编码任务中使用特征作为目标\n",
    "#dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()"
   ],
   "id": "69c2b16a789ba771",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [5000, 3].  Tensor sizes: [5000, 2]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 21\u001B[0m\n\u001B[1;32m     19\u001B[0m num_graphs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m40\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# 初始化模型\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m model \u001B[38;5;241m=\u001B[39m Network(\n\u001B[1;32m     22\u001B[0m \n\u001B[1;32m     23\u001B[0m     ntoken\u001B[38;5;241m=\u001B[39mnum_features,\n\u001B[1;32m     24\u001B[0m     d_model\u001B[38;5;241m=\u001B[39md_model,\n\u001B[1;32m     25\u001B[0m     nhead\u001B[38;5;241m=\u001B[39mnhead,\n\u001B[1;32m     26\u001B[0m     d_hid\u001B[38;5;241m=\u001B[39md_hid,\n\u001B[1;32m     27\u001B[0m     nlayers\u001B[38;5;241m=\u001B[39mnlayers,\n\u001B[1;32m     28\u001B[0m     dropout\u001B[38;5;241m=\u001B[39mdropout,\n\u001B[1;32m     29\u001B[0m \n\u001B[1;32m     30\u001B[0m     irreps_in\u001B[38;5;241m=\u001B[39mo3\u001B[38;5;241m.\u001B[39mIrreps(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5x0e\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     31\u001B[0m     irreps_hidden\u001B[38;5;241m=\u001B[39mo3\u001B[38;5;241m.\u001B[39mIrreps(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m10x0e + 5x1o\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     32\u001B[0m     irreps_out\u001B[38;5;241m=\u001B[39mo3\u001B[38;5;241m.\u001B[39mIrreps(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5x0e\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     33\u001B[0m     irreps_node_attr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     34\u001B[0m     irreps_edge_attr\u001B[38;5;241m=\u001B[39mo3\u001B[38;5;241m.\u001B[39mIrreps\u001B[38;5;241m.\u001B[39mspherical_harmonics(\u001B[38;5;241m3\u001B[39m),\n\u001B[1;32m     35\u001B[0m     layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m     36\u001B[0m     max_radius\u001B[38;5;241m=\u001B[39mmax_radius,\n\u001B[1;32m     37\u001B[0m     number_of_basis\u001B[38;5;241m=\u001B[39mnumber_of_basis,\n\u001B[1;32m     38\u001B[0m     radial_layers\u001B[38;5;241m=\u001B[39mradial_layers,\n\u001B[1;32m     39\u001B[0m     radial_neurons\u001B[38;5;241m=\u001B[39mradial_neurons,\n\u001B[1;32m     40\u001B[0m     num_neighbors\u001B[38;5;241m=\u001B[39mnum_neighbors,\n\u001B[1;32m     41\u001B[0m     num_nodes\u001B[38;5;241m=\u001B[39mnum_nodes,\n\u001B[1;32m     42\u001B[0m     reduce_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     43\u001B[0m )\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# 生成数据\u001B[39;00m\n\u001B[1;32m     46\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m generate_graph_dataset(num_graphs, num_nodes, max_radius, num_features)\n",
      "Cell \u001B[0;32mIn[3], line 298\u001B[0m, in \u001B[0;36mNetwork.__init__\u001B[0;34m(self, ntoken, d_model, nhead, d_hid, nlayers, dropout, irreps_in, irreps_hidden, irreps_out, irreps_node_attr, irreps_edge_attr, layers, max_radius, number_of_basis, radial_layers, radial_neurons, num_neighbors, num_nodes, reduce_output)\u001B[0m\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mappend(Compose(conv, gate))\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m    287\u001B[0m     Convolution(\n\u001B[1;32m    288\u001B[0m         irreps,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    296\u001B[0m     )\n\u001B[1;32m    297\u001B[0m )\n\u001B[0;32m--> 298\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer \u001B[38;5;241m=\u001B[39m TransformerModel(ntoken, d_model, nhead, d_hid, nlayers, dropout)\n",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m, in \u001B[0;36mTransformerModel.__init__\u001B[0;34m(self, ntoken, d_model, nhead, d_hid, nlayers, dropout)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m(TransformerModel, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransformer\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_encoder \u001B[38;5;241m=\u001B[39m PositionalEncoding(d_model, dropout)\n\u001B[1;32m      6\u001B[0m encoder_layers \u001B[38;5;241m=\u001B[39m TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_encoder \u001B[38;5;241m=\u001B[39m TransformerEncoder(encoder_layers, nlayers)\n",
      "Cell \u001B[0;32mIn[4], line 58\u001B[0m, in \u001B[0;36mPositionalEncoding.__init__\u001B[0;34m(self, d_model, dropout, max_len)\u001B[0m\n\u001B[1;32m     56\u001B[0m div_term \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m, d_model \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m-\u001B[39m(math\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m10000.0\u001B[39m) \u001B[38;5;241m/\u001B[39m d_model))\n\u001B[1;32m     57\u001B[0m pe \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(max_len, d_model)\n\u001B[0;32m---> 58\u001B[0m pe[:, \u001B[38;5;241m0\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msin(position \u001B[38;5;241m*\u001B[39m div_term)\n\u001B[1;32m     59\u001B[0m pe[:, \u001B[38;5;241m1\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcos(position \u001B[38;5;241m*\u001B[39m div_term)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_buffer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpe\u001B[39m\u001B[38;5;124m'\u001B[39m, pe)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [5000, 3].  Tensor sizes: [5000, 2]"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d6a34b12328a1f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:13:58.016450Z",
     "start_time": "2024-05-16T13:13:58.002049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Network1(torch.nn.Module):\n",
    "    r\"\"\"equivariant neural network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in : `e3nn.o3.Irreps` or None\n",
    "        representation of the input features\n",
    "        can be set to ``None`` if nodes don't have input features\n",
    "\n",
    "    irreps_hidden : `e3nn.o3.Irreps`\n",
    "        representation of the hidden features\n",
    "\n",
    "    irreps_out : `e3nn.o3.Irreps`\n",
    "        representation of the output features\n",
    "\n",
    "    irreps_node_attr : `e3nn.o3.Irreps` or None\n",
    "        representation of the nodes attributes\n",
    "        can be set to ``None`` if nodes don't have attributes\n",
    "\n",
    "    irreps_edge_attr : `e3nn.o3.Irreps`\n",
    "        representation of the edge attributes\n",
    "        the edge attributes are :math:`h(r) Y(\\vec r / r)`\n",
    "        where :math:`h` is a smooth function that goes to zero at ``max_radius``\n",
    "        and :math:`Y` are the spherical harmonics polynomials\n",
    "\n",
    "    layers : int\n",
    "        number of gates (non linearities)\n",
    "\n",
    "    max_radius : float\n",
    "        maximum radius for the convolution\n",
    "\n",
    "    number_of_basis : int\n",
    "        number of basis on which the edge length are projected\n",
    "\n",
    "    radial_layers : int\n",
    "        number of hidden layers in the radial fully connected network\n",
    "\n",
    "    radial_neurons : int\n",
    "        number of neurons in the hidden layers of the radial fully connected network\n",
    "\n",
    "    num_neighbors : float\n",
    "        typical number of nodes at a distance ``max_radius``\n",
    "\n",
    "    num_nodes : float\n",
    "        typical number of nodes in a graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        \n",
    "\n",
    "        irreps_in: o3.Irreps,\n",
    "        irreps_hidden: o3.Irreps,\n",
    "        irreps_out: o3.Irreps,\n",
    "        irreps_node_attr: o3.Irreps,\n",
    "        irreps_edge_attr: o3.Irreps,\n",
    "        layers: int,\n",
    "        max_radius: float,\n",
    "        number_of_basis: int,\n",
    "        radial_layers: int,\n",
    "        radial_neurons: int,\n",
    "        num_neighbors: float,\n",
    "        num_nodes: float,\n",
    "        reduce_output: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.max_radius = max_radius\n",
    "        self.number_of_basis = number_of_basis\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.num_nodes = num_nodes\n",
    "        self.reduce_output = reduce_output\n",
    "\n",
    "        self.irreps_in = o3.Irreps(irreps_in) if irreps_in is not None else None\n",
    "        self.irreps_hidden = o3.Irreps(irreps_hidden)\n",
    "        self.irreps_out = o3.Irreps(irreps_out)\n",
    "        self.irreps_node_attr = o3.Irreps(irreps_node_attr) if irreps_node_attr is not None else o3.Irreps(\"0e\")\n",
    "        self.irreps_edge_attr = o3.Irreps(irreps_edge_attr)\n",
    "\n",
    "        self.input_has_node_in = irreps_in is not None\n",
    "        self.input_has_node_attr = irreps_node_attr is not None\n",
    "\n",
    "        self.ext_z = ExtractIr(self.irreps_node_attr, \"0e\")\n",
    "        number_of_edge_features = number_of_basis + 2 * self.irreps_node_attr.count(\"0e\")\n",
    "\n",
    "        irreps = self.irreps_in if self.irreps_in is not None else o3.Irreps(\"0e\")\n",
    "\n",
    "        act = {\n",
    "            1: torch.nn.functional.silu,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "        act_gates = {\n",
    "            1: torch.sigmoid,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(layers):\n",
    "            irreps_scalars = o3.Irreps(\n",
    "                [\n",
    "                    (mul, ir)\n",
    "                    for mul, ir in self.irreps_hidden\n",
    "                    if ir.l == 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)\n",
    "                ]\n",
    "            )\n",
    "            irreps_gated = o3.Irreps(\n",
    "                [(mul, ir) for mul, ir in self.irreps_hidden if ir.l > 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)]\n",
    "            )\n",
    "            ir = \"0e\" if tp_path_exists(irreps, self.irreps_edge_attr, \"0e\") else \"0o\"\n",
    "            irreps_gates = o3.Irreps([(mul, ir) for mul, _ in irreps_gated])\n",
    "\n",
    "            gate = Gate(\n",
    "                irreps_scalars,\n",
    "                [act[ir.p] for _, ir in irreps_scalars],  # scalar\n",
    "                irreps_gates,\n",
    "                [act_gates[ir.p] for _, ir in irreps_gates],  # gates (scalars)\n",
    "                irreps_gated,  # gated tensors\n",
    "            )\n",
    "            conv = Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                gate.irreps_in,\n",
    "                number_of_edge_features,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors,\n",
    "            )\n",
    "            irreps = gate.irreps_out\n",
    "            self.layers.append(Compose(conv, gate))\n",
    "\n",
    "        self.layers.append(\n",
    "            Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                self.irreps_out,\n",
    "                number_of_edge_features,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors,\n",
    "            )\n",
    "        )\n",
    "        #self.transformer = TransformerModel(ntoken, d_model, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"evaluate the network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `torch_geometric.data.Data` or dict\n",
    "            data object containing\n",
    "            - ``pos`` the position of the nodes (atoms)\n",
    "            - ``x`` the input features of the nodes, optional\n",
    "            - ``z`` the attributes of the nodes, for instance the atom type, optional\n",
    "            - ``batch`` the graph to which the node belong, optional\n",
    "        \"\"\"\n",
    "        if \"batch\" in data:\n",
    "            batch = data[\"batch\"]\n",
    "        else:\n",
    "            batch = data[\"pos\"].new_zeros(data[\"pos\"].shape[0], dtype=torch.long)\n",
    "\n",
    "        edge_index = radius_graph(data[\"pos\"], self.max_radius, batch)\n",
    "        edge_src = edge_index[0]\n",
    "        edge_dst = edge_index[1]\n",
    "        edge_vec = data[\"pos\"][edge_src] - data[\"pos\"][edge_dst]\n",
    "        edge_sh = o3.spherical_harmonics(self.irreps_edge_attr, edge_vec, True, normalization=\"component\")\n",
    "        edge_length = edge_vec.norm(dim=1)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_length, start=0.0, end=self.max_radius, number=self.number_of_basis, basis=\"gaussian\", cutoff=False\n",
    "        ).mul(self.number_of_basis**0.5)\n",
    "        edge_attr = smooth_cutoff(edge_length / self.max_radius)[:, None] * edge_sh\n",
    "\n",
    "        if self.input_has_node_in and \"x\" in data:\n",
    "            assert self.irreps_in is not None\n",
    "            x = data[\"x\"]\n",
    "        else:\n",
    "            assert self.irreps_in is None\n",
    "            x = data[\"pos\"].new_ones((data[\"pos\"].shape[0], 1))\n",
    "\n",
    "        if self.input_has_node_attr and \"z\" in data:\n",
    "            z = data[\"z\"]\n",
    "        else:\n",
    "            assert self.irreps_node_attr == o3.Irreps(\"0e\")\n",
    "            z = data[\"pos\"].new_ones((data[\"pos\"].shape[0], 1))\n",
    "\n",
    "        scalar_z = self.ext_z(z)\n",
    "        edge_features = torch.cat([edge_length_embedded, scalar_z[edge_src], scalar_z[edge_dst]], dim=1)\n",
    "\n",
    "        for lay in self.layers:\n",
    "            x = lay(x, z, edge_src, edge_dst, edge_attr, edge_features)\n",
    "        \n",
    "        if self.reduce_output:\n",
    "            return scatter(x, batch, dim_size=int(batch.max()) + 1).div(self.num_nodes**0.5)\n",
    "        else:\n",
    "            return x"
   ],
   "id": "e3743c4f4081ec61",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:40.283217Z",
     "start_time": "2024-05-16T14:05:39.278825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_features = 5  # 每个节点的特征维度\n",
    "d_model = 5  # Transformer中的特征维度\n",
    "nhead = 5  # 多头注意力中的头数\n",
    "d_hid = 256  # 前馈网络中的隐藏单元数量\n",
    "nlayers = 3  # Transformer堆栈中的层数\n",
    "dropout = 0.1  # Dropout比率\n",
    "max_radius = 3.0  # 最大半径定义邻居\n",
    "number_of_basis = 10  # 基函数数量\n",
    "radial_layers = 2  # 径向网络层数\n",
    "radial_neurons = 64  # 每个径向层的神经元数\n",
    "num_neighbors = 6  # 平均邻居数\n",
    "num_nodes = 100  # 节点数，用于归一化\n",
    "num_graphs = 40\n",
    "# 初始化模型\n",
    "model = Network1(\n",
    "\n",
    "    \n",
    "    irreps_in=o3.Irreps(\"1x1o+2x0e\"),\n",
    "    irreps_hidden=o3.Irreps(\"10x0e + 5x1o\"),\n",
    "    irreps_out=o3.Irreps(\"1x1o+2x0e\"),\n",
    "    irreps_node_attr=None,\n",
    "    irreps_edge_attr=o3.Irreps.spherical_harmonics(3),\n",
    "    layers=3,\n",
    "    max_radius=max_radius,\n",
    "    number_of_basis=number_of_basis,\n",
    "    radial_layers=radial_layers,\n",
    "    radial_neurons=radial_neurons,\n",
    "    num_neighbors=num_neighbors,\n",
    "    num_nodes=num_nodes,\n",
    "    reduce_output=False\n",
    ")"
   ],
   "id": "428bddafebd09e5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:41.065392Z",
     "start_time": "2024-05-16T14:05:41.062904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()"
   ],
   "id": "9c5d7fc8353daeaf",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:09:05.044902Z",
     "start_time": "2024-05-16T14:09:05.040017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, dataloader, optimizer, loss_func, epochs=10):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(dataloader)):\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "\n",
    "            # 数据解包，假设 batch 是一个 Data 对象，我们需要将节点特征和边索引提取出来\n",
    "            # 以下代码需要根据你的数据加载方式做相应的调整\n",
    "            x=dataloader[i]\n",
    "\n",
    "            # 生成 src_mask，这里的 src_mask 生成需要与数据的具体形状相匹配\n",
    "            # 假设每个图的节点数相同，可以这样生成 mask\n",
    "            \n",
    "\n",
    "\n",
    "            # 执行模型前向计算\n",
    "            output = model(x)  # 注意：这里假设模型的 forward 已经适配这些输入\n",
    "\n",
    "            # 计算损失，假设我们的目标也是 x\n",
    "            loss = loss_func(output, x)\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 优化器更新参数\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)  # 累计损失\n",
    "\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {average_loss:.4f}')\n"
   ],
   "id": "a35c895ab495cc62",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:44.698565Z",
     "start_time": "2024-05-16T14:05:44.370064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader[1].x.size(-1)\n",
    "x=dataloader[1]\n",
    "output = model(x)\n",
    "type(output)\n"
   ],
   "id": "b6b312d189d37ffe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:47.208002Z",
     "start_time": "2024-05-16T14:05:47.204907Z"
    }
   },
   "cell_type": "code",
   "source": "output.shape",
   "id": "a1b2b16a9425d029",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 5])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:51.209113Z",
     "start_time": "2024-05-16T14:05:51.200995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class GraphTransformer(nn.Module):\n",
    "    def __init__(self, ntoken, d_model, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.node_encoder = nn.Linear(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        transformer_layer = TransformerEncoderLayer(d_model, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(transformer_layer, nlayers)\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        x = self.node_encoder(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        output = self.transformer_encoder(x, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 实例化模型\n",
    "modelt = GraphTransformer(ntoken=5, d_model=100, nhead=2, nhid=256, nlayers=3, dropout=0.1)\n"
   ],
   "id": "8dada741c8c4dc4e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:05:52.557747Z",
     "start_time": "2024-05-16T14:05:52.364806Z"
    }
   },
   "cell_type": "code",
   "source": "output1=modelt(output)",
   "id": "9e11cb9eae533401",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:06:09.127189Z",
     "start_time": "2024-05-16T14:06:09.119532Z"
    }
   },
   "cell_type": "code",
   "source": "type(output1)",
   "id": "413c99fff61726cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:09:09.417529Z",
     "start_time": "2024-05-16T14:09:08.648329Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, dataloader, optimizer, loss_func, epochs=5)",
   "id": "1c008c9c618d77d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size ((100, 100)) that is different to the input size (torch.Size([100, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got Data",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[93], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_model(model, dataloader, optimizer, loss_func, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "Cell \u001B[0;32mIn[92], line 21\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, dataloader, optimizer, loss_func, epochs)\u001B[0m\n\u001B[1;32m     18\u001B[0m output \u001B[38;5;241m=\u001B[39m model(x)  \u001B[38;5;66;03m# 注意：这里假设模型的 forward 已经适配这些输入\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# 计算损失，假设我们的目标也是 x\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_func(output, x)\n\u001B[1;32m     22\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# 反向传播\u001B[39;00m\n\u001B[1;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()  \u001B[38;5;66;03m# 优化器更新参数\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/loss.py:535\u001B[0m, in \u001B[0;36mMSELoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mmse_loss(\u001B[38;5;28minput\u001B[39m, target, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:3338\u001B[0m, in \u001B[0;36mmse_loss\u001B[0;34m(input, target, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   3335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3336\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3338\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbroadcast_tensors(\u001B[38;5;28minput\u001B[39m, target)\n\u001B[1;32m   3339\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mmse_loss(expanded_input, expanded_target, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/functional.py:76\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[0;34m(*tensors)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mbroadcast_tensors(tensors)\n",
      "\u001B[0;31mTypeError\u001B[0m: expected Tensor as element 1 in argument 0, but got Data"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:16:51.202668Z",
     "start_time": "2024-05-16T14:16:51.198370Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataloader)",
   "id": "e483a1f1886111fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:17:37.846217Z",
     "start_time": "2024-05-16T14:17:37.844025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(len(dataloader) * 0.7)\n",
    "test_size = int(len(dataloader) * 0.3)"
   ],
   "id": "ef59745973b3c1ef",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:17:50.125697Z",
     "start_time": "2024-05-16T14:17:50.121476Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset, test_dataset = torch.utils.data.random_split(dataloader, [train_size, test_size])\n",
   "id": "e8702dd9bb941b39",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:25:08.812410Z",
     "start_time": "2024-05-18T12:25:08.808703Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_dataset.dataset)",
   "id": "e99e0646a1c4ffd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:17:55.973302Z",
     "start_time": "2024-05-16T14:17:55.961838Z"
    }
   },
   "cell_type": "code",
   "source": "type(train_dataset)",
   "id": "18f38c55b6a901cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Subset"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:18:54.306019Z",
     "start_time": "2024-05-16T14:18:54.302109Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader",
   "id": "c4b0d03047142689",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:19:06.247213Z",
     "start_time": "2024-05-16T14:19:06.244222Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader1 = DataLoader(train_dataset, batch_size=64, shuffle=True)",
   "id": "27e2c56328826086",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df913b29841e1644"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:19:12.259556Z",
     "start_time": "2024-05-16T14:19:12.257360Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader2 = DataLoader(test_dataset, batch_size=64, shuffle=True)",
   "id": "2921cd7af84e5ec0",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:19:17.275070Z",
     "start_time": "2024-05-16T14:19:17.272662Z"
    }
   },
   "cell_type": "code",
   "source": "type(dataloader1)",
   "id": "82b392066474f394",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:28:43.651713Z",
     "start_time": "2024-05-16T14:28:43.628128Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader1.dataset[28]",
   "id": "f07f0b38fac57d67",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[127], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataloader1\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;241m28\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:391\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[0;32m--> 391\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]]\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:21:37.581846Z",
     "start_time": "2024-05-16T14:21:37.579195Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader[1]",
   "id": "b8d51a0625251b77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[100, 5], edge_index=[2, 7566], pos=[100, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:34:21.603184Z",
     "start_time": "2024-05-16T14:34:21.599070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, dataloader, optimizer, loss_func, epochs=10):\n",
    "    train = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(0, 27):\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "\n",
    "            # 数据解包，假设 batch 是一个 Data 对象，我们需要将节点特征和边索引提取出来\n",
    "            # 以下代码需要根据你的数据加载方式做相应的调整\n",
    "            x=train.dataset[i]\n",
    "            y=train.dataset[i].x\n",
    "            # 生成 src_mask，这里的 src_mask 生成需要与数据的具体形状相匹配\n",
    "            # 假设每个图的节点数相同，可以这样生成 mask\n",
    "            \n",
    "\n",
    "\n",
    "            # 执行模型前向计算\n",
    "            output = model(x)  # 注意：这里假设模型的 forward 已经适配这些输入\n",
    "            outputq = modelt(output)\n",
    "            # 计算损失，假设我们的目标也是 x\n",
    "            loss = loss_func(outputq, y)\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 优化器更新参数\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)  # 累计损失\n",
    "\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {average_loss:.4f}')"
   ],
   "id": "2abd178507e6aa87",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:35:11.666348Z",
     "start_time": "2024-05-16T14:34:22.351058Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, dataloader, optimizer, loss_func, epochs=5)",
   "id": "4a3cfabde74d2468",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 86.3561\n",
      "Epoch 2, Loss: 86.5288\n",
      "Epoch 3, Loss: 87.3641\n",
      "Epoch 4, Loss: 86.9321\n",
      "Epoch 5, Loss: 87.2541\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "Epoch 1, Loss: 33210945.8789\n",
    "Epoch 2, Loss: 15571050.4590\n",
    "Epoch 3, Loss: 11033990.7227\n",
    "Epoch 4, Loss: 8943594.9023\n",
    "Epoch 5, Loss: 7526531.2695\n",
    "'''"
   ],
   "id": "eee0bde80697957f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:34:35.549477Z",
     "start_time": "2024-05-18T12:34:35.524021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data in dataloader1:\n",
    "    type(data)"
   ],
   "id": "749fe5a8bc29ee7b",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[141], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m dataloader1:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mtype\u001B[39m(data)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:277\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m collate(batch, collate_fn_map\u001B[38;5;241m=\u001B[39mdefault_collate_fn_map)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:152\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m             \u001B[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001B[39;00m\n\u001B[1;32m    150\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:35:37.010082Z",
     "start_time": "2024-05-18T12:35:37.008016Z"
    }
   },
   "cell_type": "code",
   "source": "from torch_geometric.data import DataLoader\n",
   "id": "2863d352f1dc405c",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:35:53.764081Z",
     "start_time": "2024-05-18T12:35:53.758917Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader1 = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
   "id": "d407f56c2880dac3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:36:30.576853Z",
     "start_time": "2024-05-18T12:36:30.569382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data in dataloader1:\n",
    "    print(type(data))"
   ],
   "id": "c769257c23f1e47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.batch.DataBatch'>\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:04:17.982124Z",
     "start_time": "2024-05-18T13:04:17.970715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "import torch\n",
    "\n",
    "class TemporalGraphDataset(Dataset):\n",
    "    def __init__(self, time_series_data):\n",
    "        super(TemporalGraphDataset, self).__init__()\n",
    "        self.time_series_data = time_series_data\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.time_series_data[0].x)  # 假设所有时间步长都有相同数量的图\n",
    "\n",
    "    def get(self, idx):\n",
    "        # 提取所有时间步中索引为 idx 的图\n",
    "        return [Data(x=data.x[idx], edge_index=data.edge_index, edge_attr=data.edge_attr if hasattr(data, 'edge_attr') else None) for data in self.time_series_data]\n",
    "\n",
    "# 模拟一些数据\n",
    "time_steps = 10\n",
    "num_nodes = 5\n",
    "num_features = 3\n",
    "graphs = []\n",
    "for _ in range(time_steps):\n",
    "    x = torch.randn(num_nodes, num_features)  # Node features\n",
    "    edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))  # Edges\n",
    "    graph = Data(x=x, edge_index=edge_index)\n",
    "    graphs.append(graph)\n"
   ],
   "id": "b088a2dc580b3154",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:06:39.948043Z",
     "start_time": "2024-05-18T13:06:39.941814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# 创建 Dataset\n",
    "dataset = graphs\n",
    "\n",
    "# 创建 DataLoader\n",
    "loader = DataLoader(dataset, batch_size=1, follow_batch=['x'])\n",
    "\n",
    "# 在训练循环中使用 DataLoader\n",
    "for step, batch_graphs in enumerate(loader):\n",
    "    # `batch_graphs` 将是一个列表，其中包含批次中所有时间步的图数据\n",
    "    # 你可以在这里将它们输入到 LSTM 或其他适合处理序列数据的模型\n",
    "    pass\n"
   ],
   "id": "8f570053df9d2696",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:06:41.771280Z",
     "start_time": "2024-05-18T13:06:41.768079Z"
    }
   },
   "cell_type": "code",
   "source": "type(loader)",
   "id": "6e0edbac1516b812",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.loader.dataloader.DataLoader"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:06:46.497429Z",
     "start_time": "2024-05-18T13:06:46.495278Z"
    }
   },
   "cell_type": "code",
   "source": "loader.dataset",
   "id": "cde9af353e3ff4c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10]),\n",
       " Data(x=[5, 3], edge_index=[2, 10])]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fecf6aceb67d0043"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
